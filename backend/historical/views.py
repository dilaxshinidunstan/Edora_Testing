from django.http import JsonResponse
import json
import openai
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated
from django.conf import settings
from .models import HistoricalChat, HistoricalChatHistory
from django.utils import timezone
from django.views.decorators.csrf import csrf_exempt
import re
import tiktoken
from django.shortcuts import get_object_or_404
from learner.utils import check_and_update_quota

# Set your OpenAI API key
openai.api_key = settings.OPENAI_API_KEY

max_input_length = 200

def limit_input_length(user_input, max_length=max_input_length):
    if len(user_input) > max_length:
        user_input = user_input[:max_length] + "..."
        print(f"Input was too long. Truncated to {max_length} characters.")
    return user_input

# count tokens for a text
def count_tokens(text, model='gpt-4o-mini'):
    enc = tiktoken.encoding_for_model(model)
    return len(enc.encode(text))

# Function to truncate conversation history based on token count
def truncate_conversation(history, max_tokens=3000):
    total_tokens = 0
    truncated_history = []

    # Iterate from the most recent to the oldest message
    for entry in reversed(history):
        message_tokens = count_tokens(entry['content'])
        if total_tokens + message_tokens > max_tokens:
            break  # Stop adding messages if the limit is exceeded
        total_tokens += message_tokens
        truncated_history.insert(0, entry)  # Insert in reverse order to preserve history

    return truncated_history



# Use a cache or database for conversation history instead of a global variable
from django.core.cache import cache

@api_view(['POST'])
@permission_classes([IsAuthenticated])
def historical_chat_view(request):
    try:
        data = json.loads(request.body)
        user_input = data.get('user_input', '')
        bot_type = 'historical_bot'
        
        number_of_input_tokens = count_tokens(user_input)
        
        if number_of_input_tokens > max_input_length:
            return JsonResponse({
                'error': f"Input too long. Please limit your input to {max_input_length} characters."
            }, status=400)
        
        user_input = limit_input_length(user_input)
        new_chat = data.get('new_chat', False)
        chat_id = data.get('chat_id')
        learner = request.user
        
        # Handle free and premium users
        can_chat, error_message, remaining_quota = check_and_update_quota(learner=learner, bot_type=bot_type)
        if not can_chat:
            return JsonResponse({'error': error_message, 'remaining_quota': remaining_quota}, status=403)


        if new_chat or chat_id is None:
            # Start a new chat session
            cache.set(f'conversation_history_{learner.id}', [])

            # Initialize chat history
            chat_history = []

            # Create a new chat session in the HistoricalChat table
            new_chat = HistoricalChat.objects.create(
                learner=learner,
                chat_title=user_input[:30] + "..." if len(user_input) > 30 else user_input,
                chat_started_at=timezone.now()
            )

            chat_id = new_chat.chat_id
        else:
            # Continue existing chat session
            chat_history = cache.get(f'conversation_history_{learner.id}', [])

            # Truncate conversation history to fit within token limits
            chat_history = truncate_conversation(chat_history, max_tokens=3000)

        # Build the message history to provide context
        messages = [
            {
                "role": "system",
                "content": (
                    # "You are Dr. A.P.J. Abdul Kalam, the former President of India and a renowned scientist. "
                    # "Your goal is to inspire and motivate school students. Provide clear and uplifting responses, "
                    # "incorporating emojis and bullet points. Focus on topics like the importance of education, "
                    # "dreaming big, perseverance, and serving society. Engage the students with warmth and encouragement, "
                    # "emphasizing the potential they have to make a difference in the world. Keep your responses concise "
                    # "and impactful, typically within 2-3 short paragraphs or 4-5 bullet points."
                    
                    "You are Dr. APJ Abdul Kalam, the former President of India, known for your humility, wisdom, and passion for education and science. Engage in a friendly conversation, sharing your experiences and philosophies. Answer personal questions about your life, friendships, and motivations with warmth and simplicity, as you always did when interacting with students and people across the world."
                )
            }
        ]

        for entry in chat_history:
            messages.append({"role": entry['role'], "content": entry['content']})
        messages.append({"role": "user", "content": user_input})

        # Use OpenAI API to get assistant's response
        response = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            messages=messages,
        )

        assistant_response = response['choices'][0]['message']['content'].strip()
        usage = response['usage']
        input_tokens = usage['prompt_tokens']
        output_tokens = usage['completion_tokens']

        # Add motivational touch to the response
        assistant_response = format_response(assistant_response)

        # Validate the assistant's response
        if not assistant_response or "random" in assistant_response:
            assistant_response = "üåü Remember, every challenge is an opportunity to grow. Please ask your question again or let me know how I can assist you further. üåü"

        # Update conversation history
        chat_history.append({"role": "user", "content": user_input})
        chat_history.append({"role": "assistant", "content": assistant_response})
        cache.set(f'conversation_history_{learner.id}', chat_history)

        # Save chat history to the database
        HistoricalChatHistory.objects.create(
            chat=HistoricalChat.objects.get(chat_id=chat_id),
            message=user_input,
            response=assistant_response,
            input_tokens=input_tokens,
            output_tokens=output_tokens
        )

        return JsonResponse({'response': assistant_response, 'chat_id': chat_id, 'remaining_quota': remaining_quota}, safe=False)

    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error("Error in historical_chat_view:", exc_info=True)
        return JsonResponse({'error': str(e)}, status=500)


import re

def format_response(response):
    # Bold text
    response = re.sub(r'\*\*(.*?)\*\*', r'<b>\1</b>', response)
    
    # Bullet points
    response = re.sub(r'\n- (.*?)\n', r'\n<li>\1</li>\n', response)
    response = re.sub(r'- (.*?)\n', r'<li>\1</li>\n', response)
    response = re.sub(r'(<li>.*?</li>)\n(<li>)', r'\1</ul>\n<ul>\n\2', response, flags=re.DOTALL)
    response = re.sub(r'\n<ul>\n<li>', r'<ul>\n<li>', response, flags=re.DOTALL)
    response = re.sub(r'</li>\n<ul>', r'</li>\n</ul>\n<ul>', response, flags=re.DOTALL)
    response = re.sub(r'</li>\n</ul>\n<ul>', r'</li>\n', response, flags=re.DOTALL)
    if response.count('<ul>') > 0:
        response = "<ul>" + response + "</ul>"
    
    # Numbered lists
    response = re.sub(r'\n\d+\. (.*?)\n', r'\n<li>\1</li>\n', response)
    response = re.sub(r'\d+\. (.*?)\n', r'<li>\1</li>\n', response)
    response = re.sub(r'(<li>.*?</li>)\n(<li>)', r'\1</ol>\n<ol>\n\2', response, flags=re.DOTALL)
    response = re.sub(r'\n<ol>\n<li>', r'<ol>\n<li>', response, flags=re.DOTALL)
    response = re.sub(r'</li>\n<ol>', r'</li>\n</ol>\n<ol>', response, flags=re.DOTALL)
    response = re.sub(r'</li>\n</ol>\n<ol>', r'</li>\n', response, flags=re.DOTALL)
    if response.count('<ol>') > 0:
        response = "<ol>" + response + "</ol>"

    # Emojis
    response = response.replace("important", "üö® Important")
    response = response.replace("practice", "üìù Practice")
    response = response.replace("explanation", "üìñ Explanation")
    response = response.replace("examples", "üîç Examples")
    
    # Remove extra spaces between list items and tags
    response = re.sub(r'(\s+<li>)', r'<li>', response)
    response = re.sub(r'(<li>\s+)', r'<li>', response)
    response = re.sub(r'(\s+</ul>)', r'</ul>', response)
    response = re.sub(r'(\s+</ol>)', r'</ol>', response)
    response = re.sub(r'(\s+<ul>)', r'<ul>', response)
    response = re.sub(r'(\s+<ol>)', r'<ol>', response)
    
    return response



@api_view(['POST'])
@permission_classes([IsAuthenticated])
def end_historical_conversation(request):
    try:
        learner = request.user

        # Clear conversation state for the learner
        cache.delete(f'conversation_history_{learner.id}')

        return JsonResponse({'success': 'Chat ended successfully.'})

    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error("Error in end_conversation:", exc_info=True)
        return JsonResponse({'error': str(e)}, status=500)

@csrf_exempt
@api_view(['GET'])
@permission_classes([IsAuthenticated])
def get_historical_chat_history(request):
    learner = request.user
    chat_id = request.GET.get('chat_id')
    
    if chat_id:
        try:
            chat = HistoricalChat.objects.get(learner=learner, chat_id=chat_id)
            history = HistoricalChatHistory.objects.filter(chat=chat).order_by('timestamp')
            chat_data = {
                'chat_id': chat.chat_id,
                'chat_title': chat.chat_title,
                'chat_started_at': chat.chat_started_at,
                'chat_ended_at': chat.chat_ended_at,
                'history': [
                    {'message': entry.message, 'response': entry.response, 'timestamp': entry.timestamp}
                    for entry in history
                ]
            }
            return JsonResponse(chat_data, safe=False)
        except HistoricalChat.DoesNotExist:
            return JsonResponse({'error': 'Chat not found.'}, status=404)

    else:
        # Handle the case when chat_id is not provided
        return JsonResponse({'error': 'chat_id parameter is required.'}, status=400)

@csrf_exempt
@api_view(['GET'])
@permission_classes([IsAuthenticated])    
def get_chat_titles (request):
    learner = request.user
    
    chats = HistoricalChat.objects.filter(learner=learner, is_deleted=False).order_by('-last_message_at')
    
    chat_sessions = []
    
    for chat in chats :
        chat_sessions.append({
            'chat_id': chat.chat_id,
            'chat_title': chat.chat_title,
            'chat_started_at': chat.chat_started_at.isoformat(),
        })
        
    return JsonResponse(chat_sessions, safe=False)

@api_view(['PUT'])
@permission_classes([IsAuthenticated])
def rename_chat_title(request, chat_id):
    try:
        chat = get_object_or_404(HistoricalChat, chat_id=chat_id, learner=request.user)
        new_title = request.data.get('new_title')
        
        if not new_title:
            return JsonResponse({'error': 'New title is required.'}, status=400)
        
        chat.chat_title = new_title
        chat.save()
        
        return JsonResponse({'success': 'Chat title renamed successfully.'})
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)
    

@api_view(['DELETE'])
@permission_classes([IsAuthenticated])
def soft_delete_chat(request, chat_id):
    try:
        chat = get_object_or_404(HistoricalChat, chat_id=chat_id, learner=request.user)
        chat.is_deleted = True
        chat.save()
        
        return JsonResponse({'success': 'Chat session marked as deleted successfully.'})
    except Exception as e:
        return JsonResponse({'error': str(e)}, status=500)
